import requests
import time
import random
import json
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.webdriver.edge.service import Service as EdgeService
import pickle
import os
import csv
from datetime import datetime

# Cookieæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ç»å¯¹è·¯å¾„
COOKIE_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'pdd_cookies.pkl')

def save_cookies(driver, filename=COOKIE_FILE):
    """ä¿å­˜cookiesåˆ°æ–‡ä»¶"""
    try:
        cookies = driver.get_cookies()
        with open(filename, 'wb') as f:
            pickle.dump(cookies, f)
        print(f"Cookieså·²ä¿å­˜åˆ° {filename}")
        return True
    except Exception as e:
        print(f"ä¿å­˜cookieså¤±è´¥: {e}")
        return False

def load_cookies(driver, filename=COOKIE_FILE):
    """ä»æ–‡ä»¶åŠ è½½cookies"""
    try:
        if os.path.exists(filename):
            with open(filename, 'rb') as f:
                cookies = pickle.load(f)
            
            # æ£€æŸ¥cookiesæ˜¯å¦æœ‰æ•ˆ
            valid_cookies = 0
            for cookie in cookies:
                try:
                    # æ£€æŸ¥cookieæ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ
                    if 'name' in cookie and 'value' in cookie:
                        driver.add_cookie(cookie)
                        valid_cookies += 1
                except Exception as e:
                    print(f"è·³è¿‡æ— æ•ˆcookie: {e}")
                    continue
            
            if valid_cookies > 0:
                print(f"æˆåŠŸåŠ è½½ {valid_cookies} ä¸ªæœ‰æ•ˆcookies")
                return True
            else:
                print("æ‰€æœ‰cookieséƒ½æ— æ•ˆï¼Œå°†é‡æ–°ç™»å½•")
                return False
        else:
            print(f"Cookieæ–‡ä»¶ {filename} ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°ç™»å½•")
            return False
    except Exception as e:
        print(f"åŠ è½½cookieså¤±è´¥: {e}")
        return False



def search_goods_with_login(keyword, page=1, size=45):
    """ä½¿ç”¨ç™»å½•çŠ¶æ€æœç´¢å•†å“ï¼ˆEdgeé©±åŠ¨ï¼‰"""
    print(f"å¼€å§‹æœç´¢å•†å“: {keyword}")
    
    try:
        # é…ç½®Edgeé€‰é¡¹
        edge_options = EdgeOptions()
        edge_options.add_argument('--no-sandbox')
        edge_options.add_argument('--disable-dev-shm-usage')
        edge_options.add_argument('--disable-gpu')
        edge_options.add_argument('--window-size=1920,1080')
        edge_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        edge_options.add_experimental_option('useAutomationExtension', False)
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„Edgeé©±åŠ¨è·¯å¾„
        driver_paths = [
            "msedgedriver.exe",  # å½“å‰ç›®å½•
            os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'msedgedriver.exe'),  # é¡¹ç›®æ ¹ç›®å½•
            "C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedgedriver.exe",  # é»˜è®¤å®‰è£…è·¯å¾„
            "C:\\Program Files\\Microsoft\\Edge\\Application\\msedgedriver.exe",  # 64ä½é»˜è®¤è·¯å¾„
        ]
        
        driver = None
        for driver_path in driver_paths:
            try:
                if os.path.exists(driver_path):
                    print(f"ä½¿ç”¨Edgeé©±åŠ¨: {driver_path}")
                    driver = webdriver.Edge(service=EdgeService(driver_path), options=edge_options)
                    break
                else:
                    print(f"Edgeé©±åŠ¨ä¸å­˜åœ¨: {driver_path}")
            except Exception as e:
                print(f"åŠ è½½Edgeé©±åŠ¨å¤±è´¥ {driver_path}: {e}")
                continue
        
        if driver is None:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„Edgeé©±åŠ¨ï¼Œè¯·ç¡®ä¿msedgedriver.exeåœ¨æ­£ç¡®ä½ç½®")
            print("è¯·ä¸‹è½½ä¸æ‚¨çš„Edgeæµè§ˆå™¨ç‰ˆæœ¬åŒ¹é…çš„é©±åŠ¨ï¼š")
            print("https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/")
            return []
        
        # æ‰§è¡Œåæ£€æµ‹è„šæœ¬
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        try:
            # å…ˆè®¿é—®ä¸»é¡µ
            print("è®¿é—®æ‹¼å¤šå¤šä¸»é¡µ...")
            driver.get('https://mobile.yangkeduo.com')
            time.sleep(3)
            
            # å°è¯•åŠ è½½å·²ä¿å­˜çš„cookies
            cookies_loaded = False
            if load_cookies(driver):
                print("ä½¿ç”¨å·²ä¿å­˜çš„ç™»å½•çŠ¶æ€...")
                # åˆ·æ–°é¡µé¢ä»¥åº”ç”¨cookies
                driver.refresh()
                time.sleep(3)
                cookies_loaded = True
            else:
                print("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„ç™»å½•çŠ¶æ€ï¼Œéœ€è¦æ‰‹åŠ¨ç™»å½•")
            
            # ç›´æ¥æœç´¢å•†å“
            search_url = f'https://mobile.yangkeduo.com/search_result.html?search_key={keyword}'
            print(f"æ­£åœ¨æœç´¢: {keyword}")
            driver.get(search_url)
            time.sleep(5)
            
            # ä¿å­˜é¡µé¢æºç ç”¨äºè°ƒè¯•
            with open('pdd_search_result.html', 'w', encoding='utf-8') as f:
                f.write(driver.page_source)
            print("å·²ä¿å­˜æœç´¢ç»“æœé¡µé¢åˆ° pdd_search_result.html")
            
            # æ»‘åŠ¨é¡µé¢åŠ è½½æ›´å¤šå•†å“
            print("å¼€å§‹æ»‘åŠ¨é¡µé¢åŠ è½½æ›´å¤šå•†å“...")
            scroll_and_extract_goods(driver, size)
            
            # æå–å•†å“ä¿¡æ¯
            goods_list = extract_goods_from_search_page(driver, size)
            
            # å¦‚æœæ²¡æ‰¾åˆ°å•†å“ï¼Œæç¤ºç”¨æˆ·ç™»å½•
            if not goods_list:
                print("\n" + "="*60)
                print("âš ï¸ æœªæ‰¾åˆ°å•†å“ï¼Œéœ€è¦ç™»å½•æ‹¼å¤šå¤šè´¦å·")
                print("="*60)
                print("è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
                print("1. åœ¨æ‰“å¼€çš„æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•æ‹¼å¤šå¤š")
                print("2. ç™»å½•æˆåŠŸåï¼Œç¡®ä¿èƒ½æ­£å¸¸æœç´¢å•†å“")
                print("3. ä¿æŒæµè§ˆå™¨æ‰“å¼€çŠ¶æ€")
                print("4. å›åˆ°å‘½ä»¤è¡ŒæŒ‰å›è½¦ç»§ç»­...")
                print("="*60)
                
                input("ç™»å½•å®ŒæˆåæŒ‰å›è½¦ç»§ç»­...")
                
                # ä¿å­˜æ–°çš„cookies
                if save_cookies(driver):
                    print("âœ… æ–°çš„ç™»å½•çŠ¶æ€å·²ä¿å­˜")
                else:
                    print("âš ï¸ ä¿å­˜ç™»å½•çŠ¶æ€å¤±è´¥")
                
                # é‡æ–°æœç´¢
                print("é‡æ–°æœç´¢å•†å“...")
                driver.get(search_url)
                time.sleep(5)
                goods_list = extract_goods_from_search_page(driver, size)
            
            return goods_list
            
        finally:
            driver.quit()
            
    except Exception as e:
        print(f"æœç´¢å•†å“æ—¶å‡ºé”™: {e}")
        return []

def scroll_and_extract_goods(driver, target_count):
    """æ»‘åŠ¨é¡µé¢å¹¶åŠ è½½æ›´å¤šå•†å“"""
    try:
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_count = 0
        max_scrolls = 10  # æœ€å¤§æ»‘åŠ¨æ¬¡æ•°
        
        while scroll_count < max_scrolls:
            # æ»‘åŠ¨åˆ°é¡µé¢åº•éƒ¨
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹åŠ è½½
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                print("å·²åˆ°è¾¾é¡µé¢åº•éƒ¨ï¼Œåœæ­¢æ»‘åŠ¨")
                break
            
            last_height = new_height
            scroll_count += 1
            
            # æ£€æŸ¥å½“å‰å•†å“æ•°é‡
            current_goods = driver.find_elements(By.CSS_SELECTOR, '[class*="product"], [class*="goods"], [class*="item"]')
            print(f"æ»‘åŠ¨ {scroll_count} æ¬¡ï¼Œå½“å‰æ‰¾åˆ° {len(current_goods)} ä¸ªå•†å“")
            
            if len(current_goods) >= target_count:
                print(f"å·²è¾¾åˆ°ç›®æ ‡å•†å“æ•°é‡ {target_count}ï¼Œåœæ­¢æ»‘åŠ¨")
                break
            
            # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººå·¥æ“ä½œ
            time.sleep(random.uniform(1, 3))
        
        print(f"æ»‘åŠ¨å®Œæˆï¼Œå…±æ»‘åŠ¨ {scroll_count} æ¬¡")
        
    except Exception as e:
        print(f"æ»‘åŠ¨é¡µé¢æ—¶å‡ºé”™: {e}")



def extract_goods_from_search_page(driver, size):
    """ä»æœç´¢ç»“æœé¡µé¢æå–å•†å“ä¿¡æ¯"""
    goods_list = []
    
    # ç­‰å¾…å•†å“åˆ—è¡¨åŠ è½½
    time.sleep(5)  # å¢åŠ ç­‰å¾…æ—¶é—´
    
    print("å¼€å§‹æŸ¥æ‰¾å•†å“å…ƒç´ ...")
    
    # åªä¿ç•™æœ‰æ•ˆçš„é€‰æ‹©å™¨
    selectors_to_try = [
        '._3glhOBhU',  # PDDå•†å“å…ƒç´ çš„ä¸»è¦é€‰æ‹©å™¨
    ]
    
    found_elements = False
    for selector in selectors_to_try:
        try:
            elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if elements:
                print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                found_elements = True
                
                # æå–å•†å“ä¿¡æ¯
                valid_elements = 0
                for i, element in enumerate(elements[:size]):
                    try:
                        goods = extract_goods_from_element(element)
                        if goods and goods['goods_title'] != "æœªçŸ¥å•†å“":
                            goods_list.append(goods)
                            print(f"  ğŸ“¦ å•†å“ {i+1}: {goods['goods_title']} - {goods['goods_price']}")
                            valid_elements += 1
                    except Exception as e:
                        print(f"  âŒ æå–å•†å“ {i+1} æ—¶å‡ºé”™: {e}")
                        continue
                
                print(f"  ğŸ“Š ä» {len(elements)} ä¸ªå…ƒç´ ä¸­æå–åˆ° {valid_elements} ä¸ªæœ‰æ•ˆå•†å“")
                
                if goods_list:
                    break
            else:
                print(f"âŒ é€‰æ‹©å™¨ '{selector}' æœªæ‰¾åˆ°å…ƒç´ ")
        except Exception as e:
            print(f"âŒ é€‰æ‹©å™¨ '{selector}' å‡ºé”™: {e}")
            continue
    
    if not found_elements:
        print("âš ï¸ æ‰€æœ‰é€‰æ‹©å™¨éƒ½æœªæ‰¾åˆ°ä»»ä½•å…ƒç´ ")
        print("æ­£åœ¨ä¿å­˜é¡µé¢æºç ç”¨äºè°ƒè¯•...")
        with open('pdd_debug_page.html', 'w', encoding='utf-8') as f:
            f.write(driver.page_source)
        print("é¡µé¢æºç å·²ä¿å­˜åˆ° pdd_debug_page.html")
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å•†å“ï¼Œå°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–
    if not goods_list:
        print("å°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–å•†å“ä¿¡æ¯...")
        page_source = driver.page_source
        goods_list = extract_goods_from_page_source(page_source, size)
    
    print(f"ğŸ¯ æœ€ç»ˆæå–åˆ° {len(goods_list)} ä¸ªå•†å“")
    return goods_list

def extract_goods_from_element(element):
    """ä»Seleniumå…ƒç´ ä¸­æå–å•†å“ä¿¡æ¯"""
    try:
        # è·å–æ•´ä¸ªå•†å“å¡ç‰‡çš„æ–‡æœ¬å†…å®¹
        element_text = element.text.strip()
        print(f"[è°ƒè¯•] å•†å“å¡ç‰‡å†…å®¹ï¼š{element_text}")
        
        # æŸ¥æ‰¾å•†å“åç§° - åªä¿ç•™æœ‰æ•ˆçš„é€‰æ‹©å™¨
        name_selectors = [
            '._3ANzdjkc',  # PDDå•†å“æ ‡é¢˜çš„ä¸»è¦é€‰æ‹©å™¨
            'h3', 'h4', 'h5',
            '[class*="title"]', '[class*="name"]',
        ]
        
        name = "æœªçŸ¥å•†å“"
        for selector in name_selectors:
            try:
                name_elem = element.find_element(By.CSS_SELECTOR, selector)
                name = name_elem.text.strip()
                if name and len(name) > 2:
                    print(f"[è°ƒè¯•] ä½¿ç”¨é€‰æ‹©å™¨ {selector} æ‰¾åˆ°å•†å“åç§°ï¼š{name}")
                    break
            except:
                continue
        
        # å¦‚æœé€‰æ‹©å™¨éƒ½å¤±è´¥äº†ï¼Œå°è¯•ä»æ•´ä¸ªå…ƒç´ æ–‡æœ¬ä¸­æå–å•†å“åç§°
        if name == "æœªçŸ¥å•†å“":
            # åˆ†æå…ƒç´ æ–‡æœ¬ï¼Œæå–å•†å“åç§°
            lines = element_text.split('\n')
            for line in lines:
                line = line.strip()
                # è·³è¿‡ä»·æ ¼ã€é”€é‡ç­‰è¡Œ
                if (line and len(line) > 3 and len(line) < 100 and 
                    not any(keyword in line for keyword in ['Â¥', 'ï¿¥', 'å…ƒ', 'å—', 'å”®', 'ä»¶', 'å¥½è¯„', 'åˆ†æœŸ', 'å‘ç¥¨'])):
                    name = line
                    print(f"[è°ƒè¯•] ä»æ–‡æœ¬ä¸­æå–å•†å“åç§°ï¼š{name}")
                    break
        
        # æŸ¥æ‰¾ä»·æ ¼ - åªä¿ç•™æœ‰æ•ˆçš„é€‰æ‹©å™¨
        price_selectors = [
            '._3_U04GgA',  # PDDä»·æ ¼çš„ä¸»è¦é€‰æ‹©å™¨
            '[class*="price"]',
        ]
        
        price = "ä»·æ ¼æœªçŸ¥"
        for selector in price_selectors:
            try:
                price_elem = element.find_element(By.CSS_SELECTOR, selector)
                price_text = price_elem.text.strip()
                if 'Â¥' in price_text or 'ï¿¥' in price_text or re.search(r'\d+\.?\d*', price_text):
                    price = price_text
                    print(f"[è°ƒè¯•] ä½¿ç”¨é€‰æ‹©å™¨ {selector} æ‰¾åˆ°ä»·æ ¼ï¼š{price}")
                    break
            except:
                continue
        
        # å¦‚æœé€‰æ‹©å™¨éƒ½å¤±è´¥äº†ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ä»·æ ¼
        if price == "ä»·æ ¼æœªçŸ¥":
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡æœ¬ä¸­æå–ä»·æ ¼
            price_match = re.search(r'Â¥\s*(\d+\.?\d*)', element_text)
            if price_match:
                price = f"Â¥{price_match.group(1)}"
                print(f"[è°ƒè¯•] ä»æ–‡æœ¬ä¸­æå–ä»·æ ¼ï¼š{price}")
        
        # ä¼˜åŒ–é”€é‡æå–é€»è¾‘ - åªä¿ç•™æœ‰æ•ˆçš„é€‰æ‹©å™¨
        sales = "é”€é‡æœªçŸ¥"
        sales_selectors = [
            '._32q8gNKM',
            '[class*="sales"]',
            '[class*="sold"]',
        ]
        for selector in sales_selectors:
            try:
                elements = element.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    text = elem.text.strip()
                    if any(k in text for k in ['å”®', 'ä»¶', 'é”€é‡']):
                        sales = text
                        print(f"[è°ƒè¯•] ä½¿ç”¨é€‰æ‹©å™¨ {selector} æ‰¾åˆ°é”€é‡ï¼š{sales}")
                        break
                if sales != "é”€é‡æœªçŸ¥":
                    break
            except:
                continue
        
        # æ­£åˆ™å…œåº• - ä»æ•´ä¸ªå…ƒç´ æ–‡æœ¬ä¸­æå–é”€é‡
        if sales == "é”€é‡æœªçŸ¥":
            match = re.search(r'(æ€»å”®|å·²æ‹¼|å·²å”®|é”€é‡)[^\d]*(\d+[ä¸‡\+]*)(ä»¶)?', element_text)
            if match:
                sales = match.group(0)
                print(f"[è°ƒè¯•] ä»æ–‡æœ¬ä¸­æå–é”€é‡ï¼š{sales}")
        
        # æŸ¥æ‰¾å›¾ç‰‡
        try:
            img_elem = element.find_element(By.TAG_NAME, 'img')
            img_url = img_elem.get_attribute('src') or img_elem.get_attribute('data-src')
        except:
            img_url = ""
        
        # æŸ¥æ‰¾å•†å“ID
        goods_id = None
        try:
            link_elem = element.find_element(By.TAG_NAME, 'a')
            href = link_elem.get_attribute('href')
            match = re.search(r'goods_id=(\d+)', href)
            if match:
                goods_id = match.group(1)
        except:
            pass
        
        # æ„å»ºå•†å“ä¿¡æ¯
        goods_info = {
            'goods_id': goods_id or f"temp_{random.randint(1000, 9999)}",
            'goods_title': clean_title(name),
            'goods_price': clean_price(price),
            'goods_sales': clean_sales(sales),
            'goods_img': clean_url(img_url),
            'shop_title': 'æ‹¼å¤šå¤šè‡ªè¥',
            'shop_platform': 'æ‹¼å¤šå¤š',
            'goods_link': clean_url(f'https://mobile.yangkeduo.com/goods.html?goods_id={goods_id}' if goods_id else ''),
            'grab_time': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'page_type': 'product',
            'search_keyword': '',
            'brand': clean_brand(extract_brand_from_title(name))
        }
        
        print(f"[è°ƒè¯•] æå–çš„å•†å“ä¿¡æ¯ï¼š{goods_info}")
        return goods_info
        
    except Exception as e:
        print(f"æå–å…ƒç´ ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return None

def extract_goods_from_page_source(page_source, size):
    """ä»é¡µé¢æºç ä¸­æå–å•†å“ä¿¡æ¯"""
    goods_list = []
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾å•†å“ä¿¡æ¯
    # æŸ¥æ‰¾ä»·æ ¼æ¨¡å¼
    price_pattern = r'Â¥\s*(\d+\.?\d*)'
    prices = re.findall(price_pattern, page_source)
    
    # æŸ¥æ‰¾å¯èƒ½çš„å•†å“åç§°ï¼ˆåœ¨ä»·æ ¼é™„è¿‘çš„æ–‡æœ¬ï¼‰
    lines = page_source.split('\n')
    
    for i, line in enumerate(lines):
        if re.search(price_pattern, line):
            # å‘ä¸ŠæŸ¥æ‰¾å•†å“åç§°
            name = "æœªçŸ¥å•†å“"
            for j in range(max(0, i-5), i):
                if j < len(lines):
                    text = lines[j].strip()
                    if text and len(text) > 3 and len(text) < 100:
                        # æ’é™¤ä»·æ ¼ã€æ•°å­—ç­‰
                        if not re.search(r'Â¥|ï¿¥|\d+\.?\d*å…ƒ|\d+\.?\d*å—', text):
                            name = text
                            break
            
            price_match = re.search(price_pattern, line)
            if price_match:
                goods = {
                    'goods_id': f"temp_{random.randint(1000, 9999)}",
                    'goods_title': clean_title(name),
                    'goods_price': clean_price(price_match.group(1)),
                    'goods_sales': "é”€é‡æœªçŸ¥",
                    'goods_img': "",
                    'shop_title': 'æ‹¼å¤šå¤šè‡ªè¥',
                    'shop_platform': 'æ‹¼å¤šå¤š',
                    'goods_link': '',
                    'grab_time': datetime.now().strftime('%Y-%m-%d %H:%M'),
                    'page_type': 'product',
                    'search_keyword': '',
                    'brand': clean_brand(extract_brand_from_title(name))
                }
                goods_list.append(goods)
                
                if len(goods_list) >= size:
                    break
    
    return goods_list





def save_to_csv_pdd(data, filename='pdd_products.csv', search_keyword=''):
    """
    å°†PDDå•†å“æ•°æ®ä¿å­˜ä¸ºæ ‡å‡†CSVæ–‡ä»¶ï¼Œå­—æ®µé¡ºåºï¼š
    goods_img, goods_title, goods_price, goods_sales, shop_title, shop_platform, goods_link, grab_time, page_type, search_keyword
    """
    if not data:
        print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
        return False
    
    standard_fields = [
        'goods_img', 'goods_title', 'goods_price', 'goods_sales',
        'shop_title', 'shop_platform', 'goods_link', 'grab_time',
        'page_type', 'search_keyword'
    ]
    
    try:
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=standard_fields, quoting=csv.QUOTE_ALL)
            writer.writeheader()
            success_count = 0
            for row in data:
                mapped = {
                    'goods_img': clean_text(row.get('goods_img', '')),
                    'goods_title': clean_text(row.get('goods_title', '')),
                    'goods_price': clean_text(str(clean_price(row.get('goods_price', '')))),
                    'goods_sales': clean_text(clean_sales(row.get('goods_sales', ''))),
                    'shop_title': clean_text(row.get('shop_title', 'æ‹¼å¤šå¤šè‡ªè¥'), 50),
                    'shop_platform': clean_text('æ‹¼å¤šå¤š'),
                    'goods_link': clean_text(row.get('goods_link', '')),
                    'grab_time': clean_text(row.get('grab_time', datetime.now().strftime('%Y-%m-%d %H:%M'))),
                    'page_type': clean_text('product'),
                    'search_keyword': clean_text(search_keyword, 50)
                }
                writer.writerow(mapped)
                success_count += 1
        print(f"âœ… æˆåŠŸä¿å­˜ {success_count}/{len(data)} æ¡æ•°æ®åˆ° {filename}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def extract_brand_from_title(title):
    """ä»å•†å“æ ‡é¢˜ä¸­æå–å“ç‰Œ"""
    if not title:
        return 'æœªçŸ¥'
    
    # å¸¸è§å“ç‰Œå…³é”®è¯
    brand_keywords = [
        'è‹¹æœ', 'iPhone', 'åä¸º', 'HUAWEI', 'å°ç±³', 'MI', 'OPPO', 'vivo', 'ä¸‰æ˜Ÿ', 'SAMSUNG',
        'è£è€€', 'HONOR', 'è”æƒ³', 'Lenovo', 'realme', 'ä¸€åŠ ', 'OnePlus', 'é­…æ—', 'Meizu',
        'åŠªæ¯”äºš', 'nubia', 'ä¸­å…´', 'ZTE', 'é”¤å­', 'Smartisan', 'é»‘é²¨', 'Black Shark',
        'æå®', 'NIKE', 'é˜¿è¿ªè¾¾æ–¯', 'Adidas', 'å®‰è¸', 'Anta', 'ç‰¹æ­¥', 'Xtep',
        '361åº¦', '361Â°', 'åŒ¹å…‹', 'PEAK', 'é¸¿æ˜Ÿå°”å…‹', 'ERKE', 'ä¹”ä¸¹', 'QIAODAN'
    ]
    
    title_lower = title.lower()
    for brand in brand_keywords:
        if brand.lower() in title_lower:
            return brand
    
    return 'æœªçŸ¥'

def clean_title(text, max_length=127):
    """æ¸…æ´—å•†å“æ ‡é¢˜"""
    if not text:
        return ''
    # å»é™¤HTMLæ ‡ç­¾å’Œç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'[^\w\s\u4e00-\u9fff\-\.]', '', text)
    text = ' '.join(text.split())  # å»é™¤å¤šä½™ç©ºæ ¼
    return text[:max_length]

def clean_price(price_text):
    """æ¸…æ´—ä»·æ ¼"""
    if not price_text:
        return 0.0
    try:
        # æå–æ•°å­—å’Œå°æ•°ç‚¹
        price_num = re.sub(r'[^\d\.]', '', str(price_text))
        price_float = float(price_num)
        return round(price_float, 2)
    except (ValueError, TypeError):
        return 0.0

def clean_sales(sales_text):
    """æ¸…æ´—é”€é‡"""
    if not sales_text:
        return '0'
    # åªä¿ç•™æ•°å­—
    sales_num = re.sub(r'[^\d]', '', str(sales_text))
    return sales_num if sales_num else '0'

def clean_text(text, max_length=200):
    """æ¸…æ´—æ–‡æœ¬"""
    if not text:
        return ''
    text = str(text).replace('\n', '').replace('\r', '').strip()
    if len(text) > max_length:
        text = text[:max_length-3] + '...'
    return text

def clean_brand(brand):
    """æ¸…æ´—å“ç‰Œ"""
    if not brand or brand == 'æœªçŸ¥':
        return 'æœªçŸ¥'
    return brand.strip()

def clean_url(url):
    """æ¸…æ´—URL"""
    if not url:
        return ''
    url = str(url).strip()
    if not url.startswith(('http://', 'https://')):
        return f'https:{url}' if url.startswith('//') else f'https://{url}'
    return url

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹è¿è¡Œæ‹¼å¤šå¤šçˆ¬è™«...")
    print("æ³¨æ„ï¼šæ‹¼å¤šå¤šéœ€è¦ç™»å½•æ‰èƒ½æ­£å¸¸æœç´¢å•†å“")
    print("-" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    print("æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥Edgeé©±åŠ¨
    driver_found = False
    driver_paths = [
        "msedgedriver.exe",
        os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'msedgedriver.exe'),
    ]
    
    for path in driver_paths:
        if os.path.exists(path):
            print(f"âœ… æ‰¾åˆ°Edgeé©±åŠ¨: {path}")
            driver_found = True
            break
    
    if not driver_found:
        print("âŒ æœªæ‰¾åˆ°Edgeé©±åŠ¨æ–‡ä»¶")
        print("è¯·ä¸‹è½½msedgedriver.exeå¹¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•")
        print("ä¸‹è½½åœ°å€: https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/")
        return
    
    # æ£€æŸ¥cookieæ–‡ä»¶
    if os.path.exists(COOKIE_FILE):
        print(f"âœ… æ‰¾åˆ°cookieæ–‡ä»¶: {COOKIE_FILE}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°cookieæ–‡ä»¶ï¼Œéœ€è¦é‡æ–°ç™»å½•")
    
    print("-" * 50)
    
    # è·å–æœç´¢å…³é”®è¯
    keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆé»˜è®¤ï¼šæ‰‹æœºï¼‰: ").strip() or "æ‰‹æœº"
    
    # è·å–å•†å“æ•°é‡
    try:
        size = int(input("è¯·è¾“å…¥è¦é‡‡é›†çš„å•†å“æ•°é‡ï¼ˆé»˜è®¤ï¼š10ï¼‰: ").strip() or "50")
    except:
        size = 50
    
    print(f"å¼€å§‹æœç´¢å…³é”®è¯: {keyword}ï¼Œç›®æ ‡æ•°é‡: {size}")
    
    # ä½¿ç”¨ç™»å½•çŠ¶æ€æœç´¢å•†å“
    goods_list = search_goods_with_login(keyword, page=1, size=size)
    print(f'å…±é‡‡é›†åˆ°{len(goods_list)}ä¸ªå•†å“')
    
    if not goods_list:
        print("æ²¡æœ‰å•†å“æ•°æ®")
        return
        
    for idx, goods in enumerate(goods_list, 1):
        print(f"\nå•†å“{idx}: {goods['goods_title']}")
        print(f"  ä»·æ ¼: {goods['goods_price']}å…ƒ")
        print(f"  é”€é‡: {goods['goods_sales']}")
        print(f"  å›¾ç‰‡: {goods['goods_img']}")
        print(f"  å•†å“ID: {goods['goods_id']}")
        time.sleep(random.uniform(1, 2))  # éšæœºå»¶è¿Ÿ
    
    # ä¿å­˜ä¸ºCSV
    save_to_csv_pdd(goods_list, filename='pdd_products.csv', search_keyword=keyword)

# ç›´æ¥æ‰§è¡Œä¸»å‡½æ•°
if __name__ == '__main__':
    main()
else:
    # å½“ä½œä¸ºæ¨¡å—å¯¼å…¥æ—¶ä¹Ÿæ‰§è¡Œä¸»å‡½æ•°
    main()
